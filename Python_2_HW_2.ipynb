{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Продвинутый Python, ДЗ-2\n",
        "\n",
        "Правила игры:\n",
        "\n",
        "В домашке 8 задач, разбаловка указана в задании. Суммарно за дз можно получить 100 баллов, что равняется 10 баллам\n",
        "\n",
        "В каждой задаче необходимо реализовать функцию, которая после будет проверяться через github classroom на тестах. Сами тесты лежит в гитхабе, можете локально проверить работу функций перед сдачей\n",
        "\n",
        "Дедлайн - 7 дней после выдачи дз. Необходимо залить решеннный ноутбук в github и прислать ссылку в Anytask (без выполнения любого из пунктов работа проверяться не будет)\n",
        "\n",
        "В данной домашке нужно использовать pandas"
      ],
      "metadata": {
        "id": "5ktPX0pCqSRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/a/60658965/7286121\n",
        "\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def write_and_run(line, cell):\n",
        "    argz = line.split()\n",
        "    file = argz[-1]\n",
        "    mode = 'w'\n",
        "    if len(argz) == 2 and argz[0] == '-a':\n",
        "        mode = 'a'\n",
        "    with open(file, mode) as f:\n",
        "        f.write(cell)\n",
        "    get_ipython().run_cell(cell)"
      ],
      "metadata": {
        "id": "Rlek5byfvxPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данные"
      ],
      "metadata": {
        "id": "63di75_vqbTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом домашнем задании вам придется оказаться на месте аналитика в бразильском маркетплейсе [Olist](https://olist.com/pt-br/). Вам необходимо исследовать данные и на их основании сделать выводы, которые помогут бизнесу расцветать!\n",
        "\n",
        "Данные находятся тут в файле archive.zip"
      ],
      "metadata": {
        "id": "krcmq1NUqeCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install wget\n",
        "#перед сдачей это закомментить"
      ],
      "metadata": {
        "id": "5U4xc4-9b9XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47737bf2-0b5c-43fc-bfac-6a6be290c26a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=8fd18077439bdd87aa087cb92c94564f31d1203a5cd324b81a6edcd6d0c02ba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Код, который будет в каждом тесте, названия не менять\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import wget\n",
        "\n",
        "url = 'https://github.com/Palladain/Deep_Python/raw/main/Homeworks/Homework_1/archive.zip'\n",
        "filename = wget.download(url)\n",
        "\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "customers = pd.read_csv('olist_customers_dataset.csv')\n",
        "location = pd.read_csv('olist_geolocation_dataset.csv')\n",
        "items = pd.read_csv('olist_order_items_dataset.csv')\n",
        "payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
        "reviews = pd.read_csv('olist_order_reviews_dataset.csv')\n",
        "orders = pd.read_csv('olist_orders_dataset.csv')\n",
        "products = pd.read_csv('olist_products_dataset.csv')\n",
        "translation = pd.read_csv('product_category_name_translation.csv')\n",
        "sellers = pd.read_csv('olist_sellers_dataset.csv')"
      ],
      "metadata": {
        "id": "ItTnixKIrtHQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ван дано 9 датасетов, которые содержат в себе все данные по 100 000 заказам со всей Бразилии. Чтобы облегчить вам жизнь, вот связи по этим датасетам (файл product_category_name_translation является переводом названий категорий с португальского на английский)"
      ],
      "metadata": {
        "id": "LLos28bYrbR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/HRhd2Y0.png)"
      ],
      "metadata": {
        "id": "lXXie4hQrdhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну что же, начнем!"
      ],
      "metadata": {
        "id": "4pUMuhE1rWhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1 (10 баллов)"
      ],
      "metadata": {
        "id": "VnjVNWlFrVKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определите:\n",
        "\n",
        "* Число товаров\n",
        "\n",
        "* Среднюю стоимость товара (стоимость товара = среднее от цен в датасете items)\n",
        "\n",
        "в разрезе категорий (все категории должны быть на английском языке)\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "category | products | price\n",
        "\n",
        "value    | value      | value\n",
        "```\n",
        "\n",
        "**Обратите внимание:**\n",
        "\n",
        "Для категории portateis_cozinha_e_preparadores_de_alimentos перевод portable kitchen and food preparers\n",
        "\n",
        "Для категории pc_gamer перевод PC Gamer\n",
        "\n",
        "Для них нужно отдельно добавить перевод"
      ],
      "metadata": {
        "id": "2Qt0BXIIvXOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_1.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_1(translation, items, products):\n",
        "\n",
        "    products_copy = products.copy(deep=True)\n",
        "    items_copy = items.copy(deep=True)\n",
        "    translation_copy=translation.copy(deep=True)\n",
        "\n",
        "    new_word = pd.DataFrame({'product_category_name': ['portateis_cozinha_e_preparadores_de_alimentos', 'pc_gamer'],\n",
        "                             'product_category_name_english': ['portable kitchen and food preparers', 'PC Gamer']})\n",
        "\n",
        "    translation_copy = pd.concat([translation_copy, new_word], ignore_index=True)\n",
        "\n",
        "    new_items_copy = items_copy.groupby('product_id')['price'].mean().reset_index()\n",
        "\n",
        "    data = new_items_copy.merge(products_copy, on='product_id')\n",
        "\n",
        "    data = data.merge(translation_copy, on='product_category_name')\n",
        "    result = data.groupby('product_category_name_english').agg(products=('product_id', 'count'), price=('price', 'mean')).reset_index().rename(columns={'product_category_name_english': 'category'})\n",
        "\n",
        "    return result\n",
        "    pass"
      ],
      "metadata": {
        "id": "PWVaTwBFrkFj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Проверки\n",
        "\n",
        "res = task_1(translation, items, products)\n",
        "\n",
        "assert res[res.category == 'portable kitchen and food preparers'].price.values[0] == 186.996\n",
        "assert len(res) == 73\n",
        "assert len(res.drop_duplicates()) == 73\n",
        "assert res[res.category == 'drinks'].products.values[0] == 81\n",
        "assert res.products.sum() == 32341\n",
        "assert res.price.sum() == 12459.751444351941\n",
        "assert res[res.category == 'home_confort'].price.values[0] == 185.56926417326417"
      ],
      "metadata": {
        "id": "VgSA5JAjxngq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2 (10 баллов)"
      ],
      "metadata": {
        "id": "yUh0q89ztKMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определите для каждого продавца основную категорию их продаж (категории должны быть на английском языке)\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "seller_id | category\n",
        "\n",
        "value    | value\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3PM7DzaRzO9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_2.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_2(translation, products, items):\n",
        "\n",
        "\n",
        "    products_copy=products.copy(deep=True)\n",
        "    items_copy=items.copy(deep=True)\n",
        "    translation_copy=translation.copy(deep=True)\n",
        "\n",
        "    new_word = pd.DataFrame({'product_category_name': ['portateis_cozinha_e_preparadores_de_alimentos', 'pc_gamer'],\n",
        "                             'product_category_name_english': ['portable kitchen and food preparers', 'PC Gamer']})\n",
        "\n",
        "    translation_copy = pd.concat([translation_copy, new_word], ignore_index=True)\n",
        "\n",
        "    merged_df = items_copy.merge(products, on='product_id', how='left')\n",
        "    merged_df = merged_df.merge(translation_copy, on='product_category_name', how='left')\n",
        "\n",
        "    overall = merged_df.groupby(['seller_id', 'product_category_name_english'])['order_id'].count().reset_index()\n",
        "    overall = overall.sort_values('order_id', ascending=False).drop_duplicates('seller_id')\n",
        "    overall = overall.rename(columns={'product_category_name_english': 'category'})\n",
        "\n",
        "    return overall\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "YCKMxSNtzdxO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверки\n",
        "\n",
        "res = task_2(translation, products, items)\n",
        "assert res[res.seller_id == 'e3e15e2c0b9700561efac21c6be48066'].category.values[0] == 'housewares'\n",
        "assert res[res.seller_id == '2f73e04d12cdf0c945ded66bb3fcf6c7'].category.values[0] == 'garden_tools'\n",
        "assert len(res) == len(res.drop_duplicates())\n",
        "assert len(res) == 3035\n",
        "assert len(res[res.category == 'telephony']) == 66\n",
        "assert list(np.sort(res.groupby(\"category\").agg({\"seller_id\": \"nunique\"}).seller_id.values)) == [  1,   1,   1,   1,   1,   2,   2,   2,   2,   2,   3,   3,   4,\n",
        "         4,   4,   4,   5,   5,   5,   5,   5,   5,   6,   6,   6,   7,\n",
        "         8,  10,  12,  13,  13,  13,  14,  14,  14,  15,  16,  17,  17,\n",
        "        17,  19,  20,  20,  20,  21,  22,  26,  37,  37,  43,  46,  51,\n",
        "        54,  59,  66,  66,  78,  87,  87,  99, 101, 116, 125, 156, 216,\n",
        "       224, 256, 288, 310]"
      ],
      "metadata": {
        "id": "jfx4Lfn10Tic"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3 (10 баллов)"
      ],
      "metadata": {
        "id": "DQemvudwt4mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите долю потраченных денег по каждому штату (потраченные деньги - сумма денег по доставленным заказам, сумма по price и freight_value)\n",
        "\n",
        "*Примечание:* разбивка по штатам - по штату покупателя, процент - число от 0 до 1\n",
        "\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "state | perc\n",
        "\n",
        "value | value\n",
        "```"
      ],
      "metadata": {
        "id": "X6wytIx56ivp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_3.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_3(orders, customers, items):\n",
        "    orders_copy = orders.copy(deep=True)\n",
        "    customers_copy=customers.copy(deep=True)\n",
        "    items_copy=items.copy(deep=True)\n",
        "\n",
        "    merged_data = orders_copy.merge(customers_copy, on='customer_id')\n",
        "    merged_data = merged_data.merge(items_copy, on='order_id')\n",
        "\n",
        "    delivered_orders = merged_data[merged_data['order_status'] == 'delivered']\n",
        "    delivered_orders['total_spent'] = delivered_orders['price'] + delivered_orders['freight_value']\n",
        "\n",
        "    state_total_spent = delivered_orders.groupby('customer_state')['total_spent'].sum().reset_index()\n",
        "    state_total_spent['perc'] = state_total_spent['total_spent'] / state_total_spent['total_spent'].sum()\n",
        "    state_total_spent = state_total_spent.rename(columns={'customer_state': 'state'})\n",
        "    state_total_spent=state_total_spent.drop(columns=['total_spent'],axis=1)\n",
        "    return state_total_spent\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "WH5QCAJi3sWk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверки\n",
        "\n",
        "res = task_3(orders, customers, items)\n",
        "assert res.perc.sum() == 1\n",
        "assert res[res.state == \"RS\"].perc.values[0] == 0.055868056429816286\n",
        "assert res.sort_values(\"perc\", ascending=True).iloc[0, 1] == 0.0005862290943146945\n",
        "assert res.sort_values(\"perc\", ascending=False).iloc[0, 1] == 0.3741756035817322\n",
        "assert len(res) == 27"
      ],
      "metadata": {
        "id": "gE01dmRp5YlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e1e48a-31f0-44b6-f1ea-57b64c8bdb75"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-c74046ef0e1f>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  delivered_orders['total_spent'] = delivered_orders['price'] + delivered_orders['freight_value']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4 (10 баллов)"
      ],
      "metadata": {
        "id": "2Z5KBkyet7wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определите средний чек покупки (добавьте разбивку на стоимость самого заказ и стоимость доставки) и среднее число товаров в заказе\n",
        "\n",
        "А также определите среднее число покупок на пользователя (обратите внимание на идентификаторы)"
      ],
      "metadata": {
        "id": "9klcqoBj80DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_4.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_4(items, orders, customers):\n",
        "    items_copy = items.copy(deep=True)\n",
        "    orders_copy = orders.copy(deep=True)\n",
        "    customers_copy = customers.copy(deep=True)\n",
        "\n",
        "    order_price_mean = items_copy.groupby('order_id')['price'].sum().mean()\n",
        "    delivery_cost_stat = items_copy.groupby('order_id')['freight_value'].sum().mean()\n",
        "    items_per_order = items_copy.groupby('order_id').size().mean()\n",
        "\n",
        "    customer_orders = pd.merge(orders_copy, customers_copy, on='customer_id')\n",
        "    orders_per_customer = customer_orders['order_id'].nunique()/customers['customer_unique_id'].nunique()\n",
        "\n",
        "    return order_price_mean, delivery_cost_stat, items_per_order, orders_per_customer"
      ],
      "metadata": {
        "id": "lMqosgB-7OeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1217d6c5-b81f-4ec2-f563-3e3bfe7d1fac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137.7540763788945, 22.823561713254815, 1.1417306873695092, 1.0348089410589412)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "\n",
        "res = task_4(items, orders, customers)\n",
        "assert res == (137.7540763788945, 22.823561713254815, 1.1417306873695092, 1.0348089410589412)"
      ],
      "metadata": {
        "id": "ManEB8qf7lm_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5 (10 баллов)"
      ],
      "metadata": {
        "id": "pEHsUeuYuPsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитайте CSAT (customer satisfaction - средняя оценка ревью) и отобразите средний CSAT по дням в период с апреля 2017 по апрель 2018 года\n",
        "\n",
        "Все манипуляции с датой необходимо сделать с помощью datetime и dateutil\n",
        "\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "date | csat\n",
        "\n",
        "\"YYYY-MM-DD\" | value\n",
        "```"
      ],
      "metadata": {
        "id": "cGX_GxAs9Fww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_5.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dateutil.parser import parse\n",
        "import datetime\n",
        "\n",
        "def task_5(reviews):\n",
        "    reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])\n",
        "\n",
        "    low_border_time = pd.to_datetime('2017-04-01')\n",
        "    high_border_time = pd.to_datetime('2018-04-30')\n",
        "\n",
        "    filtered_reviews = reviews[(reviews['review_creation_date'] >= low_border_time) & (reviews['review_creation_date'] <= high_border_time)]\n",
        "\n",
        "    daily_csat = filtered_reviews.groupby(filtered_reviews['review_creation_date'].dt.date)['review_score'].mean().reset_index()\n",
        "    daily_csat.columns = ['date', 'csat']\n",
        "    daily_csat.date = daily_csat.date.apply(lambda x: str(x))\n",
        "\n",
        "    return daily_csat\n",
        "    pass"
      ],
      "metadata": {
        "id": "Fu31Qrod9M_4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверки\n",
        "res = task_5(reviews)\n",
        "assert res.date.min() == '2017-04-01'\n",
        "assert res.date.max() == '2018-04-30'\n",
        "assert res.csat.sum() == 1551.8881071384853\n",
        "assert res[res.date == '2017-07-11'].csat.values[0] == 4.291390728476821\n",
        "assert res[res.date == '2018-02-09'].csat.values[0] == 3.992156862745098\n",
        "assert res[res.csat == 3.6814814814814816].date.values[0] == '2018-02-25'"
      ],
      "metadata": {
        "id": "UK4r71Vh-Pfu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 6 (10 баллов)"
      ],
      "metadata": {
        "id": "L-rho7C0uUTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрите, как быстро отвечают пользователи (сделайте аггреграцию по числу дней ответа) и какая средняя оценка\n",
        "\n",
        "Все манипуляции со временем нужно делать через datetime и dateutil\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "days | csat | orders\n",
        "\n",
        "value | value | value\n",
        "```\n",
        "\n",
        "Результаты должны быть отсориртированы по дня по возрастанию"
      ],
      "metadata": {
        "id": "3H-lma4hL-sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_6.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dateutil.parser import parse\n",
        "import datetime\n",
        "\n",
        "def task_6(reviews):\n",
        "    review_copy = reviews.copy()\n",
        "\n",
        "    review_copy['review_creation_date'] = pd.to_datetime(review_copy['review_creation_date']).dt.date\n",
        "    review_copy['review_answer_timestamp'] = pd.to_datetime(review_copy['review_answer_timestamp']).dt.date\n",
        "    review_copy['days'] = (review_copy['review_answer_timestamp'] - review_copy['review_creation_date']).dt.days\n",
        "\n",
        "    csat = review_copy.groupby('days').agg({'review_score': 'mean', 'order_id': 'count'}).reset_index()\n",
        "    csat.rename(columns={'review_score': 'csat', 'order_id': 'orders'}, inplace=True)\n",
        "    csat.sort_values('days', inplace=True)\n",
        "\n",
        "    return csat\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "BCjO8WQgMeGC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверки\n",
        "res = task_6(reviews)\n",
        "assert res.orders.sum() == 99224\n",
        "assert np.all(res.days.values == np.sort(res.days.values))\n",
        "assert len(res) == 214\n",
        "assert res.days.min() == 0\n",
        "assert res.days.max() == 518\n",
        "assert res[res.days == 233].csat.values[0] == 3.0\n",
        "assert res[res.days == 87].orders.values[0] == 4"
      ],
      "metadata": {
        "id": "b_zq1nfxOvZa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 7 (10 баллов)"
      ],
      "metadata": {
        "id": "bc-MZgP2udIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выделите все заказы, где не проставлено поле order_delivered_customer_date. Замените его на дату '2999-12-31'"
      ],
      "metadata": {
        "id": "JxkpI1l0QO0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_7.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_7(orders):\n",
        "\n",
        "    missing_delivered_date = orders['order_delivered_customer_date'].isnull()\n",
        "    orders.loc[missing_delivered_date, 'order_delivered_customer_date'] = '2999-12-31'\n",
        "\n",
        "    return orders\n",
        "    pass"
      ],
      "metadata": {
        "id": "oqIpnXvbP3FZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Проверки\n",
        "\n",
        "res = task_7(orders)\n",
        "assert len(res[res.order_delivered_customer_date.isna()]) == 0\n",
        "assert len(res) == 99441\n",
        "assert len(res[res.order_delivered_customer_date == '2999-12-31']) == 2965"
      ],
      "metadata": {
        "id": "k6z59EMXWLkm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 8 (30 баллов)"
      ],
      "metadata": {
        "id": "TVbTTB9nuiHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определите топ-10 продавцов, у которых больше 100 заказов, отсылающие чаще всего свою посылку в другие регионы (считаются только доставленные заказы)\n",
        "\n",
        "Чаще всего отсылают = самый большой процент отправленных заказов в другой штат\n",
        "\n",
        "Табличка, которая у вас должна получиться:\n",
        "\n",
        "```\n",
        "seller_id | share\n",
        "\n",
        "value | value\n",
        "```"
      ],
      "metadata": {
        "id": "zeRxv6FDVeVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_and_run task_8.py\n",
        "\n",
        "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def task_8(orders, items, sellers, customers):\n",
        "\n",
        "    orders_copy=orders.copy(deep=True)\n",
        "    items_copy=items.copy(deep=True)\n",
        "    sellers_copy=sellers.copy(deep=True)\n",
        "    customers_copy=customers.copy(deep=True)\n",
        "\n",
        "    combined_data = orders_copy.merge(items_copy, on='order_id').merge(sellers_copy, on='seller_id')\n",
        "\n",
        "\n",
        "    delivered_orders = combined_data[combined_data['order_status'] == 'delivered']\n",
        "    delivered_orders = delivered_orders.merge(customers, on='customer_id')\n",
        "\n",
        "    overall_orders_seller = delivered_orders.groupby(\"seller_id\")[\"order_id\"].nunique().reset_index()\n",
        "    overall_orders_seller.columns = ['seller_id', 'total_orders']\n",
        "\n",
        "\n",
        "    orders_other_states = delivered_orders[delivered_orders['customer_state'] != delivered_orders['seller_state']]\n",
        "    orders_other_states_seller = orders_other_states.groupby(\"seller_id\")[\"order_id\"].nunique().reset_index()\n",
        "    orders_other_states_seller.columns = ['seller_id', 'orders_to_other_states']\n",
        "\n",
        "\n",
        "    seller_orders_data = overall_orders_seller.merge(orders_other_states_seller, on='seller_id', how='left')\n",
        "    seller_orders_data=seller_orders_data.fillna(0.0)\n",
        "\n",
        "    seller_orders_data['share'] = seller_orders_data['orders_to_other_states'] / seller_orders_data['total_orders']\n",
        "    top_sellers = seller_orders_data[seller_orders_data['total_orders'] > 100].sort_values(by='share', ascending=False).head(10).reset_index()\n",
        "    return top_sellers[['seller_id', 'share']]\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "Nv1eFCg5WnlD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверки\n",
        "\n",
        "res = task_8(orders, items, sellers, customers)\n",
        "assert np.all(res.share.values == np.sort(res.share.values)[::-1])\n",
        "assert res.share.values[0] == 0.9743589743589743\n",
        "assert res.share.values[-1] == 0.9356435643564357\n",
        "assert res.seller_id.values[5] == '1b4c3a6f53068f0b6944d2d005c9fc89'\n",
        "assert res.seller_id.values[2] == '06a2c3af7b3aee5d69171b0e14f0ee87'\n",
        "assert res.share.sum() == 9.519118744616716"
      ],
      "metadata": {
        "id": "1bC_uAYIbRrn"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}